{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rich.progress import track\n",
    "\n",
    "class Tanh:\n",
    "    def activate(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def derivative(self, x):\n",
    "        return 1 - self.activate(x) ** 2\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, len_inputs, neurons, function, last=False):\n",
    "        shape = neurons, len_inputs + 1\n",
    "        self.weights = np.random.uniform(-0.5, 0.5, size=shape)\n",
    "        self.f = function\n",
    "        self.last = last\n",
    "        self.idx = None\n",
    "        self.neurons = neurons\n",
    "        self.len_inputs = len_inputs\n",
    "    \n",
    "    def forward(self, layer_input):\n",
    "        self.input = layer_input\n",
    "        self.net = self.input.dot(self.weights.T)\n",
    "        self.output = self.f.activate(self.net)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, target, alpha, previous_delta=None, previous_weigth=None):\n",
    "        if self.last:\n",
    "            self.delta = (target - self.output) * self.f.derivative(self.net)\n",
    "        else:\n",
    "            self.delta = (np.delete(previous_delta.dot(previous_weigth).T, 0) * self.f.derivative(self.net))\n",
    "        \n",
    "        self.weights += np.array([self.delta]).T * np.array([self.input]) * alpha\n",
    "        \n",
    "        return self.delta, self.weights\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"({self.idx}ยบ Layer, Neurons: {self.neurons}, Last: {self.last})\"\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, *layers: Layer):\n",
    "        self.layers = list(layers)\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            layer.idx = idx + 1\n",
    "        self.layers[-1].last = True\n",
    "        self.len_inputs = self.layers[0].len_inputs\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"NeuralNetwork (Num_Layers: {len(self.layers)}, Len_Inputs: {self.len_inputs}, Layers: {self.layers})\"\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        resp = []\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            resp.append((idx+1, layer.weights))\n",
    "        return resp\n",
    "        \n",
    "    def _forward(self, x_input):\n",
    "        #input_layer = x_input\n",
    "        input_layer = np.append(1, x_input)\n",
    "        for layer in self.layers:\n",
    "            out_layer = layer.forward(input_layer)\n",
    "            input_layer = np.append(1, out_layer)\n",
    "            \n",
    "        return out_layer\n",
    "    \n",
    "    def _backward(self, y, alpha):\n",
    "        for layer in reversed(self.layers):\n",
    "            if layer.last:\n",
    "                previous_delta, previous_weigth = layer.backward(y, alpha)\n",
    "            else:\n",
    "                previous_delta, previous_weigth = layer.backward(y, alpha, previous_delta, previous_weigth)\n",
    "    \n",
    "    def fit(self, x_train, y_train, epochs=2000, alpha=0.05):\n",
    "\n",
    "        for epoch in track(range(epochs), description=\"Processing...\"):\n",
    "            outputs = []\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                out = self._forward(x)\n",
    "                self._backward(y, alpha)\n",
    "                outputs.append(out)\n",
    "                \n",
    "            errors = np.array([sum(error) for error in (y_train - outputs) ** 2])\n",
    "            self.mean_squared_error = sum(errors) / len(errors)\n",
    "            \n",
    "            if not epoch % 100:\n",
    "                print(f\"MSE: {self.mean_squared_error}\")\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        out = self._forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_neurons(n):\n",
    "    res = [-1] * 10\n",
    "    res[n] = 1\n",
    "    return res\n",
    "\n",
    "data_train = pl.read_csv(\"train.csv\")\n",
    "\n",
    "y_train = np.array(data_train.drop_in_place(\"label\"))\n",
    "y_train = np.array([number_to_neurons(y) for y in y_train])\n",
    "\n",
    "x_train = np.array([row for row in data_train.rows()]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf23b39d97146158a5ccd42211e6741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MSE: 1.0254692630158078\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MSE: 1.0254692630158078\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rede = NeuralNetwork(\n",
    "    Layer(len_inputs=784, neurons=28, function=Tanh()),\n",
    "    Layer(len_inputs=28, neurons=10, function=Tanh()),\n",
    ")\n",
    "rede.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(rede, x, y, total, inicial=0):\n",
    "    points = 0\n",
    "    for idx in range(1000,total):\n",
    "        correct = np.argmax(y[idx])\n",
    "        predict = np.argmax(rede.predict(x[idx]))\n",
    "        if correct == predict:\n",
    "            points += 1\n",
    "\n",
    "    return points/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.21666666666667"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(rede, x_train, y_train, 42_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(rede, n_cam):\n",
    "    with open(\"weights.npy\", \"wb\") as f:\n",
    "        for idx in range(n_cam):\n",
    "            np.save(f, rede.layers[idx].weights)\n",
    "\n",
    "def load_weights(rede, n_cam):\n",
    "    with open(\"weights.npy\", \"rb\") as f:\n",
    "        for idx in range(n_cam):\n",
    "            rede.layers[idx].weights = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(rede, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_predict(rede, n):\n",
    "    data_test = pl.read_csv(\"test.csv\")\n",
    "    x_test = np.array([row for row in data_test.rows()]) / 255\n",
    "    kaggle_df = pl.read_csv(\"sample_submission.csv\")\n",
    "    predicts = []\n",
    "    for idx in range(28_000):\n",
    "        predict = np.argmax(rede.predict(x_test[idx]))\n",
    "        predicts.append(predict)\n",
    "\n",
    "    df_predicts = pl.DataFrame({\n",
    "        \"Label\": predicts\n",
    "    })\n",
    "\n",
    "    submission = kaggle_df.update(df_predicts)\n",
    "    submission.write_csv(f\"predicts_kaggle_{n}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_predict(rede, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predizer_garrancho(garrancho):\n",
    "    if garrancho is not None:\n",
    "        x = garrancho.reshape(1, 784) / 255\n",
    "        return np.argmax(rede.predict(x))\n",
    "    \n",
    "\n",
    "gr.Interface(fn=predizer_garrancho, \n",
    "             inputs=\"sketchpad\",\n",
    "             outputs=\"textbox\",\n",
    "             ).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1,  1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [ 1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1,  1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_train\n",
    "y = y_train\n",
    "data = list(zip(x_train,y_train))\n",
    "np.random.shuffle(data)\n",
    "x_train,y_train = zip(*data)\n",
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
